# Rough-Terrain-Navigation-using-MBRL
This project develops a robust model-based reinforcement learning framework for long-horizon trajectory planning of wheeled robots in rough, unstructured terrain under significant model uncertainty. By combining uncertainty-aware dynamics learning, closed-loop prediction, and divergence-constrained optimization, the approach prevents planners from exploiting model errors and enables dynamically feasible, non-myopic navigation. The result is more reliable and strategically effective autonomous traversal in challenging environments such as off-road, disaster-response, and exploratory settings.
